{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Load data**"
      ],
      "metadata": {
        "id": "2ij_9bv2tjE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLr6Osd93Vfn",
        "outputId": "f69fa774-46a2-4f90-90fb-60e7c1b61734"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nyEbyvUcp3wd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "3d934116-8572-4c74-94fe-5835da803683"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentiment         ids                          date      flag  \\\n",
              "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "5          0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
              "6          0  1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
              "7          0  1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                              tweet  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  \n",
              "5         joy_wolf                      @Kwesidei not the whole crew   \n",
              "6          mybirch                                        Need a hug   \n",
              "7             coZZ  @LOLTrish hey  long time no see! Yes.. Rains a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-131c76f7-dde9-4fd9-8347-261bbbac1de2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811592</td>\n",
              "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mybirch</td>\n",
              "      <td>Need a hug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811594</td>\n",
              "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>coZZ</td>\n",
              "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-131c76f7-dde9-4fd9-8347-261bbbac1de2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-131c76f7-dde9-4fd9-8347-261bbbac1de2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-131c76f7-dde9-4fd9-8347-261bbbac1de2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "DATASET_COLUMNS=['sentiment','ids','date','flag','user','tweet']\n",
        "df = pd.read_csv('/content/drive/MyDrive/training.1600000.processed.noemoticon.csv', encoding=\"ISO-8859-1\", names=DATASET_COLUMNS)\n",
        "df.head(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Drop columns that are not useful for our modeling**"
      ],
      "metadata": {
        "id": "JzuHFQrQtous"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['ids', 'date', 'flag', 'user'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "61jJYSKarUm1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7cee9872-9d79-4c59-f110-bb6f1d9273f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sentiment                                              tweet\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fe40fe6-557e-4255-97bb-247e255a6aab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fe40fe6-557e-4255-97bb-247e255a6aab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fe40fe6-557e-4255-97bb-247e255a6aab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fe40fe6-557e-4255-97bb-247e255a6aab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Preprocessing**"
      ],
      "metadata": {
        "id": "lzDmPIbUtxMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map the sentiment values to positive, negative. 0 is mapped to negative, and four is mapped to positive\n",
        "label_to_sentiment = {0:\"Negative\", 4:\"Positive\"}\n",
        "def label_decoder(label):\n",
        "     return label_to_sentiment[label]\n",
        "df.sentiment = df.sentiment.apply(lambda x: label_decoder(x))"
      ],
      "metadata": {
        "id": "0BX-eOeOrYRa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import nltk package and download the stopwords\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "# We filter out the english language stopwrds\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n"
      ],
      "metadata": {
        "id": "-UK7PxLgrkzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839c10b5-9c02-46e9-eefc-791d0267f8ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming/lemmatization refers to the process of extracting the root word. For example, can write ‘play’ as ‘playing,’ ‘played,’ ‘plays’ in different tenses. But the actual meaning is the same. We need to convert these into the root word for easier modelling. We can use the Snowball stemmer from the NLTK package to implement this."
      ],
      "metadata": {
        "id": "DwrYPrcnrue1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "f-xr7c6wrvDt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For removing the non-alphabetic characters, we can use regex expressions."
      ],
      "metadata": {
        "id": "kHCiTk27rypd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text_cleaning_regex = \"@S+|https?:S+|http?:S|[^A-Za-z0-9]+\""
      ],
      "metadata": {
        "id": "B937Q--lrzFS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us define a function that will perform regex filtering, stop word removal, and stemming on all the tweets. Note that in NLP,  we describe the processed words as ‘tokens.’ Each tweet will be passed on to the function shown below."
      ],
      "metadata": {
        "id": "xm2CIzq5r5_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweets(text, stem=False):\n",
        "  # Text passed to the regex equatio\n",
        "  text = re.sub(text_cleaning_regex, ' ', str(text).lower()).strip()\n",
        "  # Empty list created to store final tokens\n",
        "  tokens = []\n",
        "  for token in text.split():\n",
        "    # check if the token is a stop word or not\n",
        "    if token not in stop_words:\n",
        "      if stem:\n",
        "        # Paased to the snowball stemmer\n",
        "        tokens.append(stemmer.stem(token))\n",
        "      else:\n",
        "        # A\n",
        "        tokens.append(token)\n",
        "  return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "WqsKww5Rr5WA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above funtion, the text is converted into all lower case; white spaces are stripped and passed to the equation. The hyperlinks will remove non-alphanumeric characters. An empty list can be created to store the final tokens. The sentence is split into words, and each word is checked if it belongs to the list of stop words or not. After that, stemming is performed, and the word is stored in the list.  In the end, the tokens in the list are joined and returned."
      ],
      "metadata": {
        "id": "msAL7HEZsB6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.tweet = df.tweet.apply(lambda x: clean_tweets(x))\n"
      ],
      "metadata": {
        "id": "qKtV7joqsE1s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Modeling**"
      ],
      "metadata": {
        "id": "6lp9eVrataPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "train_data, test_data = train_test_split(df, test_size=0.2,random_state=16)\n",
        "print(\"Train Data size:\", len(train_data))\n",
        "print(\"Test Data size\", len(test_data))"
      ],
      "metadata": {
        "id": "XyqEs0ivr_IB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9851a962-082a-40de-951d-9102f47be152"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data size: 1280000\n",
            "Test Data size 320000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1 Tokenization & Label Encoding**\n"
      ],
      "metadata": {
        "id": "3p3SZJQbuTHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization refers to splitting the given sentence into a list of tokens, indexed or vectorized."
      ],
      "metadata": {
        "id": "p71hdDq3uqif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data.tweet)\n",
        "word_index = tokenizer.word_index\n",
        "keys = list(word_index.keys())\n",
        "print(keys[:10])\n",
        "values = list(word_index.values())\n",
        "print(values[:10])\n",
        "# This is a dictionary where each word is mapped with a particular index, starting from 1.\n",
        "vocab_size = len(word_index) + 1\n",
        "print(\"Vocabulary Size :\", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8hmQcVCumKt",
        "outputId": "2ce8dd95-8d18-4b12-ad39-a64193d74f2f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['good', 'day', 'get', 'like', 'go', 'quot', 'http', 'today', 'work', 'love']\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "Vocabulary Size : 565660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be applying a sequence model to this data. For this, we need to pass inputs of the same size. To achieve this, we will use the `pad_sequences()` function. This will return us sequences of a constant size, which can be passed as a parameter. "
      ],
      "metadata": {
        "id": "fOWg9x1IveOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# The tokens are converted into sequences and then passed to the pad_sequences() function\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(train_data.tweet),maxlen = 30)\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(test_data.tweet),maxlen = 30)"
      ],
      "metadata": {
        "id": "MGzpyNiPugML"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize encoder class and fit it upon the training dataset’s labels (sentiment column). After this, we extract the sentiment from train data to make y_test, y_train by encoding and reshaping"
      ],
      "metadata": {
        "id": "ShkLLqvsxN05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding\n",
        "labels = ['Negative', 'Positive']\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_data.sentiment.to_list())\n",
        "y_train = encoder.transform(train_data.sentiment.to_list())\n",
        "y_test = encoder.transform(test_data.sentiment.to_list())\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)"
      ],
      "metadata": {
        "id": "uI6MjIDaxOXK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2 Representing words with vectors**"
      ],
      "metadata": {
        "id": "ukr4Nvz8zo4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ultimate aim is that the talks with similar meanings are closer to each other than the irrelevant words in the vector representation. The distance between the words could be measured by cosine similarity. For example, the words’ travelling’ and ‘vacation’ will be represented by vectors closer to each other."
      ],
      "metadata": {
        "id": "hrOpD8pUzw0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The gloVe is a pretrained word embedding model, and we can download it.\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFc6d89Fz5ft",
        "outputId": "5034d1c4-8e1e-4937-9d9d-35ca6d4a5714"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-03 20:03:19--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-02-03 20:03:19--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-02-03 20:03:19--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.10MB/s    in 2m 39s  \n",
            "\n",
            "2023-02-03 20:05:58 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# create a dictionary mapping the words with GloVe vector representations.\n",
        "embeddings_index = {}\n",
        "# opening the downloaded glove embeddings file\n",
        "f = open('glove.6B.300d.txt')\n",
        "for line in f:\n",
        "    # For each line file, the words are split and stored in a list\n",
        "    values = line.split()\n",
        "    word = value = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HHP34yo0Dj8",
        "outputId": "933c11f4-f640-4fd8-a635-cdfe1dc6c508"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that in the tokenizing section, we had gotten a dictionary ‘word_index’, where each word is mapped to an index in the vocabulary. Now, we will map those vocab indices with the glove representations."
      ],
      "metadata": {
        "id": "6zkWVMO-0U5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an matrix with zeroes of shape vocab x embedding dimension\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "# Iterate through word, index in the dictionary\n",
        "for word, i in word_index.items():\n",
        "    # extract the corresponding vector for the vocab indice of same word\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Storing it in a matrix\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "71-8qtHq0WB5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3 Intitialize weights**"
      ],
      "metadata": {
        "id": "YeNvur120kXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have a matrix that can initialize the weights. We will be using the embedding layer of Keras."
      ],
      "metadata": {
        "id": "BN0XS6c_0bM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "embedding_layer = tf.keras.layers.Embedding(vocab_size,300,weights=[embedding_matrix],\n",
        "                                          input_length=30,trainable=False)"
      ],
      "metadata": {
        "id": "ewgAwgXV0reP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.0 Model Architecture (LSTM) & Training**"
      ],
      "metadata": {
        "id": "LZj_X4nt039H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with the embedding layer defined previously, and it inputs the sequences and gives word embeddings. These embeddings are then passed on to the convolution layer, which will convert them into small feature vectors. Next, we have the bidirectional LSTM layer. After the LSTM layers, we have a couple of Dense (fully connected layers) for classification purposes. We use a sigmoid activation function before the final output"
      ],
      "metadata": {
        "id": "HVKUOlGh16PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# The Input layer \n",
        "sequence_input = Input(shape=(30,), dtype='int32')\n",
        "# Inputs passed to the embedding layer\n",
        "embedding_sequences = embedding_layer(sequence_input)\n",
        "# dropout and conv layer \n",
        "x = SpatialDropout1D(0.2)(embedding_sequences)\n",
        "x = Conv1D(64, 5, activation='relu')(x)\n",
        "# Passed on to the LSTM layer\n",
        "x = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# Passed on to activation layer to get final output\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "model = tf.keras.Model(sequence_input, outputs)"
      ],
      "metadata": {
        "id": "B38fDWLM1FWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5eb5ea2-a038-4500-ef84-2b0e221f2571"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import plot_loss\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1, min_lr = 0.0001, monitor = 'val_loss',verbose = 1)\n",
        "model_save_path = \"/content/drive/MyDrive/sentimentAnalysis/model\"\n",
        "checkpoint = ModelCheckpoint(model_save_path, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"auto\", period=1)\n",
        "plot = plot_loss.TrainingPlot()\n",
        "\n",
        "training = model.fit(x_train, y_train, batch_size=1024, epochs=10,\n",
        "                    validation_data=(x_test, y_test), callbacks=[ReduceLROnPlateau, checkpoint, plot])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzC68te52La-",
        "outputId": "63ae2105-702a-4bd8-ff6b-fdf8249accb9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.7854\n",
            "Epoch 1: val_loss improved from inf to 0.45736, saving model to /content/drive/MyDrive/sentimentAnalysis/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1250/1250 [==============================] - 163s 128ms/step - loss: 0.4507 - accuracy: 0.7854 - val_loss: 0.4574 - val_accuracy: 0.7814 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.7863\n",
            "Epoch 2: val_loss did not improve from 0.45736\n",
            "1250/1250 [==============================] - 147s 118ms/step - loss: 0.4491 - accuracy: 0.7863 - val_loss: 0.4581 - val_accuracy: 0.7814 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4483 - accuracy: 0.7872\n",
            "Epoch 3: val_loss did not improve from 0.45736\n",
            "1250/1250 [==============================] - 146s 117ms/step - loss: 0.4483 - accuracy: 0.7872 - val_loss: 0.4612 - val_accuracy: 0.7817 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.7876\n",
            "Epoch 4: val_loss did not improve from 0.45736\n",
            "1250/1250 [==============================] - 144s 115ms/step - loss: 0.4474 - accuracy: 0.7876 - val_loss: 0.4595 - val_accuracy: 0.7828 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.7880\n",
            "Epoch 5: val_loss improved from 0.45736 to 0.45588, saving model to /content/drive/MyDrive/sentimentAnalysis/model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1250/1250 [==============================] - 156s 125ms/step - loss: 0.4465 - accuracy: 0.7880 - val_loss: 0.4559 - val_accuracy: 0.7825 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.7885\n",
            "Epoch 6: val_loss did not improve from 0.45588\n",
            "1250/1250 [==============================] - 144s 116ms/step - loss: 0.4459 - accuracy: 0.7885 - val_loss: 0.4583 - val_accuracy: 0.7823 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4450 - accuracy: 0.7890\n",
            "Epoch 7: val_loss did not improve from 0.45588\n",
            "1250/1250 [==============================] - 141s 113ms/step - loss: 0.4450 - accuracy: 0.7890 - val_loss: 0.4577 - val_accuracy: 0.7823 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4444 - accuracy: 0.7890\n",
            "Epoch 8: val_loss did not improve from 0.45588\n",
            "1250/1250 [==============================] - 141s 113ms/step - loss: 0.4444 - accuracy: 0.7890 - val_loss: 0.4566 - val_accuracy: 0.7820 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.7896\n",
            "Epoch 9: val_loss did not improve from 0.45588\n",
            "1250/1250 [==============================] - 141s 113ms/step - loss: 0.4438 - accuracy: 0.7896 - val_loss: 0.4583 - val_accuracy: 0.7829 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.4434 - accuracy: 0.7899\n",
            "Epoch 10: val_loss did not improve from 0.45588\n",
            "1250/1250 [==============================] - 140s 112ms/step - loss: 0.4434 - accuracy: 0.7899 - val_loss: 0.4581 - val_accuracy: 0.7827 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tweet_sentiment(score):\n",
        "    return \"Positive\" if score>0.5 else \"Negative\"\n",
        "scores = model.predict(x_test[:1], verbose=1, batch_size=10000)\n",
        "model_predictions = [predict_tweet_sentiment(score) for score in scores]\n",
        "print(x_test[:1], model_predictions[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgPFLVIp_Rwf",
        "outputId": "282f52e2-d963-428f-f843-48e1a6f9d111"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 436ms/step\n",
            "[[     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0 112939   3089     27    285\n",
            "    1453    201    209  24860  10673 310448   1284   3089   3927    419]] ['Positive']\n"
          ]
        }
      ]
    }
  ]
}